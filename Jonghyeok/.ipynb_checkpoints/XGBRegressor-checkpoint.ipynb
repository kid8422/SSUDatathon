{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cff46-83fb-4a7b-ac55-02171559da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install, import\n",
    "from sklearn.datasets import load_boston  #boston_data를 예제로 하겠다. \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "pip install xgboost\n",
    "import xgboost\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import data \n",
    "data = load_boston()\n",
    "x, y = data.data, data.target\n",
    "\n",
    "# scaling \n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit(x).transform(x)\n",
    "y_scaled = scaler.fit(y).transform(y)\n",
    "\n",
    "# train & test_data\n",
    "x_train, x_test, y_train, y_test = train_test_split( x_scaled, y_scaled, test_size = 0.2)\n",
    "\n",
    "# 하이퍼 파라미터 튜닝, 그리드 서치 \n",
    "xgb1 = xgboost.XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(x_train, y_train)\n",
    "\n",
    "# define the model, booster = 'gbtree'\n",
    "xgb_model = xgboost.XGBRegressor(booster = 'gbtree',\n",
    "                                 nthread = 4, \n",
    "                                 learning_rate = 0.05, \n",
    "                                 max_depth = 6, \n",
    "                                 min_child_weight = 4, \n",
    "                                 silent = 1, \n",
    "                                 subsample = 0.7,\n",
    "                                 colsample_bytree = 0.7,\n",
    "                                 n_estimators = 500)\n",
    "\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# 시각화 \n",
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "xgboost.plot_importance(xgb_model, ax=ax)\n",
    "\n",
    "# score\n",
    "predictions = xgb_model.predict(x_test)\n",
    "print(xgb_model.score(x_train, y_train))\n",
    "print(xgb_model.score(x_test, y_test))\n",
    "plt.plot(y_test)\n",
    "plt.plot(xgb_model.predict(x_test))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "[출처] XGBoost Regression python|작성자 greeny"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "datathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
